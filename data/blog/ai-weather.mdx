---
title: Building a Weather Advice Microservice with Next.js and OpenAI
date: '2023-05-16'
summary: 'Create a microservice with real-time weather updates and contextually relevant advice using Next.js and OpenAI'
tags: [learning, engineering, AI, serverless, Next.js, React, OpenAI]
images: ['/static/images/weather.webp']
---

![weather shot](/static/images/weather.webp)

In the world of modern web development, there are numerous exciting opportunities and challenges. One such endeavor is the creation of a unique microservice that provides real-time weather updates and generates contextually relevant advice based on the current weather conditions. This project utilizes Next.js, a React-based framework, and the powerful capabilities of OpenAI.

## Understanding the Task

The goal of this microservice is to fetch real-time weather data based on the user's IP address and generate suitable advice using OpenAI. By combining Next.js, serverless functions, and OpenAI, we can create a dynamic and responsive web application.

### Building the Weather Microservice

The cornerstone of the microservice is the implementation of a `WeatherTable` function, which is a React functional component. This function utilizes the `useState` and `useEffect` hooks to fetch data from serverless functions and display it in the front-end. The microservice also incorporates Axios for making HTTP requests and the React Tooltip library to enhance the user experience.

### Serverless Functions

Two serverless functions power the microservice: `getWeatherData` and `getAdvice`. The `getWeatherData` function fetches weather data based on the user's IP address, while the `getAdvice` function leverages the OpenAI API to generate advice based on the weather data. Both functions are deployed as serverless functions.

Here is an example of the `getAdvice` function:

```javascript
async function handler(req, res) {
  const { weatherData } = req.body

  if (weatherData) {
    const prompt = `In the voice of Willard Scott without saying so, and presence based on current time as ${weatherData.location.localtime} and based on current weather described as ${weatherData.current.condition.text} and weather conditions consisting of Cloud Coverage is ${weatherData.current.cloud}% and Temperature is ${weatherData.current.temp_f}F and Humidity is ${weatherData.current.humidity}% and Precipitation for the day is ${weatherData.current.precip_in} inches and Current Wind Speed is ${weatherData.current.wind_mph} mph and Winds are Gusting at ${weatherData.current.gust_mph} mph, any advice on what I should pack when going outside, as in outerwear, and/or an umbrella? Limit 140 characters.`
    try {
      const { data } = await openai.createCompletion({
        model: 'text-davinci-003',
        prompt,
        temperature: 0.7, // Adjust based on desired randomness vs. coherence
        max_tokens: 100, // Adjust based on desired response length
        top_p: 1,
        frequency_penalty: 0.2, // Fine-tune to control repetitiveness
        presence_penalty: 0.6, // Fine-tune to encourage relevant responses
        stop: '\\n',
      })
      const advice = data.choices[0].text.trim()
      res.status(200).json({ advice })
    } catch (error) {
      console.error(error)
      res.status(500).json({ message: 'An error occurred while fetching advice' })
    }
  } else {
    res.status(400).json({ message: 'Invalid request data' })
  }
}
```

Here's how the API call is constructed to work. The prompt is designed to provide specific context to the AI, including current weather details, and asks it to generate advice on what to pack when going outside. The parameters of the `openai.createCompletion` function are defined as follows:

- `model: 'text-davinci-003'`: Specifies the model used for generating the advice. In this case, we are using GPT-3's 'text-davinci-003' model.
- `prompt`: The input string that will be used as a base for generating the AI's response.
- `temperature: 0.7`: Controls the randomness of the AI's responses. A higher value will yield more random outputs, while a lower value results in more deterministic outputs.
- `max_tokens: 100`: Limits the length of the generated output to 100 tokens.
- `top_p: 1`: Used for nucleus sampling, a method of random sampling which selects the next word in the generated text from a restricted pool of promising candidates, instead of the entire distribution.
- `frequency_penalty: 0.2`: Adjusts the likelihood of the AI generating frequent vs. rare phrases.
- `presence_penalty: 0.6`: Adjusts the likelihood of the AI generating context-relevant vs. context-irrelevant responses.
- `stop: '\\n'`: Instructs the AI to end the text generation when it encounters a newline character.

Once the advice is generated, it is sent back to the front-end of the application and displayed to the user. If an error occurs during the process, the function will return a 500 status code along with an error message.

By using the serverless architecture and leveraging the power of OpenAI, we can deliver a dynamic, contextually aware weather advice microservice. The serverless approach provided scalability and cost-effectiveness, while the use of Next.js and React provides responsive user interface.
